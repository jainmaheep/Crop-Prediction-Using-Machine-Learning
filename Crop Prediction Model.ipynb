{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba530012-2086-4801-bbfd-ffc7ff3a0f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Pipeline\n",
      "Training Accuracy Score: 86.2%\n",
      "Validation Accuracy Score: 84.3%\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       banana       1.00      1.00      1.00       103\n",
      " black lentil       0.36      0.30      0.33       103\n",
      " bottle gourd       0.98      0.89      0.93       102\n",
      "      brinjal       0.97      1.00      0.99        99\n",
      "       carrot       1.00      1.00      1.00        87\n",
      "  cauliflower       0.99      0.95      0.97        95\n",
      "    chickpeas       1.00      1.00      1.00        89\n",
      "       chilli       0.88      0.97      0.92       108\n",
      "finger millet       0.42      0.56      0.48        90\n",
      "    groundnut       0.99      0.98      0.98        88\n",
      "  kidneybeans       1.00      1.00      1.00       107\n",
      "  lady finger       0.95      0.94      0.95       105\n",
      "        maize       0.98      1.00      0.99       109\n",
      "       millet       0.54      0.36      0.43       106\n",
      "       papaya       1.00      0.98      0.99       104\n",
      "   red lentil       0.28      0.24      0.26       106\n",
      "         rice       0.99      1.00      1.00       107\n",
      "      sorghum       0.97      0.96      0.96        99\n",
      "     soyabean       0.96      0.98      0.97       100\n",
      "       tomato       1.00      0.98      0.99        94\n",
      "  watermeleon       0.96      0.99      0.98       108\n",
      "        wheat       0.98      0.97      0.97        93\n",
      "yellow lentil       0.29      0.41      0.34        98\n",
      "\n",
      "     accuracy                           0.84      2300\n",
      "    macro avg       0.85      0.85      0.84      2300\n",
      " weighted avg       0.85      0.84      0.84      2300\n",
      "\n",
      "Confusion Matrix:\n",
      "     (0) (1) (2) (3) (4) (5) (6) (7) (8) (9) (10) (11) (12) (13) (14) (15) (16) (17) (18) (19) (20) (21) (22)\n",
      "(0)  103    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(1)    0   31    0    0    0    0    0    0    0    0    0    0    0    0    0   29    0    0    0    0    0    0   43 \n",
      "(2)    0    0   91    1    0    0    0    9    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(3)    0    0    0   99    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(4)    0    0    0    0   87    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(5)    0    0    0    0    0   90    0    0    0    0    0    1    0    0    0    0    1    0    0    0    3    0    0 \n",
      "(6)    0    0    0    0    0    0   89    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(7)    0    0    0    0    0    0    0  105    0    0    0    3    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(8)    0    4    0    0    0    0    0    3   50    0    0    0    0   32    0    0    0    0    0    0    0    0    1 \n",
      "(9)    0    0    0    0    0    0    0    0    0   86    0    0    0    0    0    0    0    0    2    0    0    0    0 \n",
      "(10)    0    0    0    0    0    0    0    0    0    0  107    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(11)    0    0    0    0    0    0    0    3    0    0    0   99    0    0    0    0    0    0    2    0    1    0    0 \n",
      "(12)    0    0    0    0    0    0    0    0    0    0    0    0  109    0    0    0    0    0    0    0    0    0    0 \n",
      "(13)    0    0    0    0    0    0    0    0   68    0    0    0    0   38    0    0    0    0    0    0    0    0    0 \n",
      "(14)    0    0    2    0    0    0    0    0    0    0    0    0    0    0  102    0    0    0    0    0    0    0    0 \n",
      "(15)    0   26    0    0    0    0    0    0    0    0    0    0    0    0    0   25    0    0    0    0    0    0   55 \n",
      "(16)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  107    0    0    0    0    0    0 \n",
      "(17)    0    0    0    0    0    0    0    0    0    0    0    0    2    0    0    0    0   95    0    0    0    2    0 \n",
      "(18)    0    0    0    0    0    0    0    0    0    1    0    0    0    1    0    0    0    0   98    0    0    0    0 \n",
      "(19)    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   92    0    0    0 \n",
      "(20)    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0  107    0    0 \n",
      "(21)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    3    0    0    0   90    0 \n",
      "(22)    0   24    0    0    0    0    0    0    0    0    0    0    0    0    0   34    0    0    0    0    0    0   40 \n",
      "Model: Pipeline\n",
      "Training Accuracy Score: 83.5%\n",
      "Validation Accuracy Score: 81.2%\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       banana       1.00      1.00      1.00       103\n",
      " black lentil       0.36      0.29      0.32       103\n",
      " bottle gourd       0.94      0.77      0.85       102\n",
      "      brinjal       0.87      1.00      0.93        99\n",
      "       carrot       0.99      1.00      0.99        87\n",
      "  cauliflower       1.00      0.94      0.97        95\n",
      "    chickpeas       1.00      1.00      1.00        89\n",
      "       chilli       0.87      0.91      0.89       108\n",
      "finger millet       0.39      0.50      0.44        90\n",
      "    groundnut       0.85      0.97      0.90        88\n",
      "  kidneybeans       1.00      1.00      1.00       107\n",
      "  lady finger       0.93      0.96      0.94       105\n",
      "        maize       0.93      0.99      0.96       109\n",
      "       millet       0.50      0.33      0.40       106\n",
      "       papaya       0.99      0.95      0.97       104\n",
      "   red lentil       0.25      0.20      0.22       106\n",
      "         rice       0.99      1.00      1.00       107\n",
      "      sorghum       0.86      0.84      0.85        99\n",
      "     soyabean       0.97      0.85      0.90       100\n",
      "       tomato       1.00      0.96      0.98        94\n",
      "  watermeleon       0.96      1.00      0.98       108\n",
      "        wheat       0.89      0.85      0.87        93\n",
      "yellow lentil       0.27      0.42      0.33        98\n",
      "\n",
      "     accuracy                           0.81      2300\n",
      "    macro avg       0.82      0.81      0.81      2300\n",
      " weighted avg       0.82      0.81      0.81      2300\n",
      "\n",
      "Confusion Matrix:\n",
      "     (0) (1) (2) (3) (4) (5) (6) (7) (8) (9) (10) (11) (12) (13) (14) (15) (16) (17) (18) (19) (20) (21) (22)\n",
      "(0)  103    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(1)    0   30    0    0    0    0    0    0    0    0    0    0    0    0    0   31    0    0    0    0    0    0   42 \n",
      "(2)    0    0   79    9    1    0    0   12    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0 \n",
      "(3)    0    0    0   99    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(4)    0    0    0    0   87    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(5)    0    0    0    0    0   89    0    0    0    1    0    0    0    0    0    0    1    0    0    0    4    0    0 \n",
      "(6)    0    0    0    0    0    0   89    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(7)    0    0    0    3    0    0    0   98    0    0    0    7    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(8)    0    4    0    0    0    0    0    0   45    0    0    0    0   33    0    0    0    0    0    0    0    0    8 \n",
      "(9)    0    0    0    0    0    0    0    0    0   85    0    0    0    1    0    0    0    0    2    0    0    0    0 \n",
      "(10)    0    0    0    0    0    0    0    0    0    0  107    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(11)    0    0    0    0    0    0    0    3    0    0    0  101    0    0    0    0    0    0    1    0    0    0    0 \n",
      "(12)    0    0    0    0    0    0    0    0    0    0    0    0  108    0    0    0    0    0    0    0    0    1    0 \n",
      "(13)    0    0    0    0    0    0    0    0   71    0    0    0    0   35    0    0    0    0    0    0    0    0    0 \n",
      "(14)    0    0    5    0    0    0    0    0    0    0    0    0    0    0   99    0    0    0    0    0    0    0    0 \n",
      "(15)    0   26    0    0    0    0    0    0    0    0    0    0    0    0    0   21    0    0    0    0    0    0   59 \n",
      "(16)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  107    0    0    0    0    0    0 \n",
      "(17)    0    0    0    0    0    0    0    0    0    0    0    0    7    0    0    0    0   83    0    0    0    9    0 \n",
      "(18)    0    0    0    0    0    0    0    0    0   14    0    0    0    1    0    0    0    0   85    0    0    0    0 \n",
      "(19)    0    0    0    3    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0   90    0    0    0 \n",
      "(20)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  108    0    0 \n",
      "(21)    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0   13    0    0    0   79    0 \n",
      "(22)    0   24    0    0    0    0    0    0    0    0    0    0    0    0    0   33    0    0    0    0    0    0   41 \n",
      "Model: Pipeline\n",
      "Training Accuracy Score: 91.7%\n",
      "Validation Accuracy Score: 86.8%\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       banana       1.00      1.00      1.00       103\n",
      " black lentil       0.29      0.39      0.33       103\n",
      " bottle gourd       0.96      0.92      0.94       102\n",
      "      brinjal       0.99      1.00      0.99        99\n",
      "       carrot       1.00      1.00      1.00        87\n",
      "  cauliflower       1.00      0.98      0.99        95\n",
      "    chickpeas       1.00      1.00      1.00        89\n",
      "       chilli       0.93      0.95      0.94       108\n",
      "finger millet       0.77      0.52      0.62        90\n",
      "    groundnut       0.99      1.00      0.99        88\n",
      "  kidneybeans       1.00      1.00      1.00       107\n",
      "  lady finger       0.95      0.98      0.97       105\n",
      "        maize       0.98      1.00      0.99       109\n",
      "       millet       0.70      0.87      0.77       106\n",
      "       papaya       0.99      0.97      0.98       104\n",
      "   red lentil       0.29      0.28      0.29       106\n",
      "         rice       0.99      1.00      1.00       107\n",
      "      sorghum       1.00      0.97      0.98        99\n",
      "     soyabean       1.00      0.99      0.99       100\n",
      "       tomato       1.00      0.99      0.99        94\n",
      "  watermeleon       0.99      1.00      1.00       108\n",
      "        wheat       0.99      1.00      0.99        93\n",
      "yellow lentil       0.22      0.15      0.18        98\n",
      "\n",
      "     accuracy                           0.87      2300\n",
      "    macro avg       0.87      0.87      0.87      2300\n",
      " weighted avg       0.87      0.87      0.87      2300\n",
      "\n",
      "Confusion Matrix:\n",
      "     (0) (1) (2) (3) (4) (5) (6) (7) (8) (9) (10) (11) (12) (13) (14) (15) (16) (17) (18) (19) (20) (21) (22)\n",
      "(0)  103    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(1)    0   40    0    0    0    0    0    0    0    0    0    0    0    0    0   40    0    0    0    0    0    0   23 \n",
      "(2)    0    0   94    1    0    0    0    6    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0 \n",
      "(3)    0    0    0   99    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(4)    0    0    0    0   87    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(5)    0    0    0    0    0   93    0    0    0    0    0    0    0    0    0    0    1    0    0    0    1    0    0 \n",
      "(6)    0    0    0    0    0    0   89    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(7)    0    0    1    0    0    0    0  103    0    0    0    4    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(8)    0    3    0    0    0    0    0    0   47    0    0    0    0   40    0    0    0    0    0    0    0    0    0 \n",
      "(9)    0    0    0    0    0    0    0    0    0   88    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(10)    0    0    0    0    0    0    0    0    0    0  107    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(11)    0    0    0    0    0    0    0    2    0    0    0  103    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(12)    0    0    0    0    0    0    0    0    0    0    0    0  109    0    0    0    0    0    0    0    0    0    0 \n",
      "(13)    0    0    0    0    0    0    0    0   14    0    0    0    0   92    0    0    0    0    0    0    0    0    0 \n",
      "(14)    0    0    3    0    0    0    0    0    0    0    0    0    0    0  101    0    0    0    0    0    0    0    0 \n",
      "(15)    0   47    0    0    0    0    0    0    0    0    0    0    0    0    0   30    0    0    0    0    0    0   29 \n",
      "(16)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  107    0    0    0    0    0    0 \n",
      "(17)    0    0    0    0    0    0    0    0    0    0    0    0    2    0    0    0    0   96    0    0    0    1    0 \n",
      "(18)    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0   99    0    0    0    0 \n",
      "(19)    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0   93    0    0    0 \n",
      "(20)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  108    0    0 \n",
      "(21)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   93    0 \n",
      "(22)    0   50    0    0    0    0    0    0    0    0    0    0    0    0    0   33    0    0    0    0    0    0   15 \n",
      "Model: Pipeline\n",
      "Training Accuracy Score: 100.0%\n",
      "Validation Accuracy Score: 88.2%\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       banana       1.00      1.00      1.00       103\n",
      " black lentil       0.35      0.36      0.35       103\n",
      " bottle gourd       0.97      1.00      0.99       102\n",
      "      brinjal       1.00      1.00      1.00        99\n",
      "       carrot       1.00      1.00      1.00        87\n",
      "  cauliflower       0.99      0.99      0.99        95\n",
      "    chickpeas       1.00      1.00      1.00        89\n",
      "       chilli       1.00      0.98      0.99       108\n",
      "finger millet       0.64      0.68      0.66        90\n",
      "    groundnut       1.00      1.00      1.00        88\n",
      "  kidneybeans       1.00      1.00      1.00       107\n",
      "  lady finger       0.99      1.00      1.00       105\n",
      "        maize       1.00      1.00      1.00       109\n",
      "       millet       0.71      0.67      0.69       106\n",
      "       papaya       1.00      0.99      1.00       104\n",
      "   red lentil       0.33      0.32      0.33       106\n",
      "         rice       1.00      0.99      1.00       107\n",
      "      sorghum       1.00      1.00      1.00        99\n",
      "     soyabean       1.00      1.00      1.00       100\n",
      "       tomato       1.00      0.99      0.99        94\n",
      "  watermeleon       0.99      1.00      1.00       108\n",
      "        wheat       1.00      1.00      1.00        93\n",
      "yellow lentil       0.36      0.36      0.36        98\n",
      "\n",
      "     accuracy                           0.88      2300\n",
      "    macro avg       0.88      0.88      0.88      2300\n",
      " weighted avg       0.88      0.88      0.88      2300\n",
      "\n",
      "Confusion Matrix:\n",
      "     (0) (1) (2) (3) (4) (5) (6) (7) (8) (9) (10) (11) (12) (13) (14) (15) (16) (17) (18) (19) (20) (21) (22)\n",
      "(0)  103    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(1)    0   37    0    0    0    0    0    0    0    0    0    0    0    0    0   32    0    0    0    0    0    0   34 \n",
      "(2)    0    0  102    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(3)    0    0    0   99    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(4)    0    0    0    0   87    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(5)    0    0    0    0    0   94    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0 \n",
      "(6)    0    0    0    0    0    0   89    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(7)    0    0    1    0    0    0    0  106    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(8)    0    0    0    0    0    0    0    0   61    0    0    0    0   29    0    0    0    0    0    0    0    0    0 \n",
      "(9)    0    0    0    0    0    0    0    0    0   88    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(10)    0    0    0    0    0    0    0    0    0    0  107    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(11)    0    0    0    0    0    0    0    0    0    0    0  105    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(12)    0    0    0    0    0    0    0    0    0    0    0    0  109    0    0    0    0    0    0    0    0    0    0 \n",
      "(13)    0    0    0    0    0    0    0    0   35    0    0    0    0   71    0    0    0    0    0    0    0    0    0 \n",
      "(14)    0    0    1    0    0    0    0    0    0    0    0    0    0    0  103    0    0    0    0    0    0    0    0 \n",
      "(15)    0   43    0    0    0    0    0    0    0    0    0    0    0    0    0   34    0    0    0    0    0    0   29 \n",
      "(16)    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0  106    0    0    0    0    0    0 \n",
      "(17)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   99    0    0    0    0    0 \n",
      "(18)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  100    0    0    0    0 \n",
      "(19)    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   93    0    0    0 \n",
      "(20)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  108    0    0 \n",
      "(21)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   93    0 \n",
      "(22)    0   27    0    0    0    0    0    0    0    0    0    0    0    0    0   36    0    0    0    0    0    0   35 \n",
      "Model: Pipeline\n",
      "Training Accuracy Score: 90.0%\n",
      "Validation Accuracy Score: 88.0%\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       banana       1.00      1.00      1.00       103\n",
      " black lentil       0.32      0.32      0.32       103\n",
      " bottle gourd       0.98      0.99      0.99       102\n",
      "      brinjal       0.99      1.00      0.99        99\n",
      "       carrot       1.00      1.00      1.00        87\n",
      "  cauliflower       1.00      0.98      0.99        95\n",
      "    chickpeas       1.00      1.00      1.00        89\n",
      "       chilli       0.98      1.00      0.99       108\n",
      "finger millet       0.86      0.62      0.72        90\n",
      "    groundnut       1.00      1.00      1.00        88\n",
      "  kidneybeans       1.00      1.00      1.00       107\n",
      "  lady finger       1.00      0.98      0.99       105\n",
      "        maize       1.00      1.00      1.00       109\n",
      "       millet       0.74      0.92      0.82       106\n",
      "       papaya       1.00      0.98      0.99       104\n",
      "   red lentil       0.20      0.15      0.17       106\n",
      "         rice       0.99      1.00      1.00       107\n",
      "      sorghum       1.00      0.99      0.99        99\n",
      "     soyabean       1.00      1.00      1.00       100\n",
      "       tomato       1.00      1.00      1.00        94\n",
      "  watermeleon       0.99      1.00      1.00       108\n",
      "        wheat       0.99      1.00      0.99        93\n",
      "yellow lentil       0.28      0.35      0.31        98\n",
      "\n",
      "     accuracy                           0.88      2300\n",
      "    macro avg       0.88      0.88      0.88      2300\n",
      " weighted avg       0.88      0.88      0.88      2300\n",
      "\n",
      "Confusion Matrix:\n",
      "     (0) (1) (2) (3) (4) (5) (6) (7) (8) (9) (10) (11) (12) (13) (14) (15) (16) (17) (18) (19) (20) (21) (22)\n",
      "(0)  103    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(1)    0   33    0    0    0    0    0    0    0    0    0    0    0    0    0   29    0    0    0    0    0    0   41 \n",
      "(2)    0    0  101    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(3)    0    0    0   99    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(4)    0    0    0    0   87    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(5)    0    0    0    0    0   93    0    0    0    0    0    0    0    0    0    0    1    0    0    0    1    0    0 \n",
      "(6)    0    0    0    0    0    0   89    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(7)    0    0    0    0    0    0    0  108    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(8)    0    0    0    0    0    0    0    0   56    0    0    0    0   34    0    0    0    0    0    0    0    0    0 \n",
      "(9)    0    0    0    0    0    0    0    0    0   88    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(10)    0    0    0    0    0    0    0    0    0    0  107    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(11)    0    0    0    0    0    0    0    2    0    0    0  103    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(12)    0    0    0    0    0    0    0    0    0    0    0    0  109    0    0    0    0    0    0    0    0    0    0 \n",
      "(13)    0    0    0    0    0    0    0    0    9    0    0    0    0   97    0    0    0    0    0    0    0    0    0 \n",
      "(14)    0    0    2    0    0    0    0    0    0    0    0    0    0    0  102    0    0    0    0    0    0    0    0 \n",
      "(15)    0   42    0    0    0    0    0    0    0    0    0    0    0    0    0   16    0    0    0    0    0    0   48 \n",
      "(16)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  107    0    0    0    0    0    0 \n",
      "(17)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   98    0    0    0    1    0 \n",
      "(18)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  100    0    0    0    0 \n",
      "(19)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   94    0    0    0 \n",
      "(20)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  108    0    0 \n",
      "(21)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   93    0 \n",
      "(22)    0   29    0    0    0    0    0    0    0    0    0    0    0    0    0   35    0    0    0    0    0    0   34 \n",
      "Model: Pipeline\n",
      "Training Accuracy Score: 89.6%\n",
      "Validation Accuracy Score: 88.4%\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       banana       1.00      1.00      1.00       103\n",
      " black lentil       0.36      0.45      0.40       103\n",
      " bottle gourd       0.98      0.96      0.97       102\n",
      "      brinjal       0.99      1.00      0.99        99\n",
      "       carrot       1.00      1.00      1.00        87\n",
      "  cauliflower       1.00      0.97      0.98        95\n",
      "    chickpeas       1.00      1.00      1.00        89\n",
      "       chilli       0.96      0.99      0.97       108\n",
      "finger millet       1.00      0.52      0.69        90\n",
      "    groundnut       1.00      0.99      0.99        88\n",
      "  kidneybeans       1.00      1.00      1.00       107\n",
      "  lady finger       0.99      0.98      0.99       105\n",
      "        maize       0.97      1.00      0.99       109\n",
      "       millet       0.71      1.00      0.83       106\n",
      "       papaya       1.00      0.98      0.99       104\n",
      "   red lentil       0.25      0.10      0.15       106\n",
      "         rice       0.99      1.00      1.00       107\n",
      "      sorghum       1.00      0.96      0.98        99\n",
      "     soyabean       0.99      1.00      1.00       100\n",
      "       tomato       1.00      1.00      1.00        94\n",
      "  watermeleon       0.98      1.00      0.99       108\n",
      "        wheat       0.99      1.00      0.99        93\n",
      "yellow lentil       0.32      0.44      0.37        98\n",
      "\n",
      "     accuracy                           0.88      2300\n",
      "    macro avg       0.89      0.88      0.88      2300\n",
      " weighted avg       0.89      0.88      0.88      2300\n",
      "\n",
      "Confusion Matrix:\n",
      "     (0) (1) (2) (3) (4) (5) (6) (7) (8) (9) (10) (11) (12) (13) (14) (15) (16) (17) (18) (19) (20) (21) (22)\n",
      "(0)  103    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(1)    0   46    0    0    0    0    0    0    0    0    0    0    0    0    0   15    0    0    0    0    0    0   42 \n",
      "(2)    0    0   98    1    0    0    0    3    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(3)    0    0    0   99    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(4)    0    0    0    0   87    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(5)    0    0    0    0    0   92    0    0    0    0    0    0    0    0    0    0    1    0    0    0    2    0    0 \n",
      "(6)    0    0    0    0    0    0   89    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(7)    0    0    0    0    0    0    0  107    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(8)    0    0    0    0    0    0    0    0   47    0    0    0    0   43    0    0    0    0    0    0    0    0    0 \n",
      "(9)    0    0    0    0    0    0    0    0    0   87    0    0    0    0    0    0    0    0    1    0    0    0    0 \n",
      "(10)    0    0    0    0    0    0    0    0    0    0  107    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(11)    0    0    0    0    0    0    0    2    0    0    0  103    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(12)    0    0    0    0    0    0    0    0    0    0    0    0  109    0    0    0    0    0    0    0    0    0    0 \n",
      "(13)    0    0    0    0    0    0    0    0    0    0    0    0    0  106    0    0    0    0    0    0    0    0    0 \n",
      "(14)    0    0    2    0    0    0    0    0    0    0    0    0    0    0  102    0    0    0    0    0    0    0    0 \n",
      "(15)    0   44    0    0    0    0    0    0    0    0    0    0    0    0    0   11    0    0    0    0    0    0   51 \n",
      "(16)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  107    0    0    0    0    0    0 \n",
      "(17)    0    0    0    0    0    0    0    0    0    0    0    0    3    0    0    0    0   95    0    0    0    1    0 \n",
      "(18)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  100    0    0    0    0 \n",
      "(19)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   94    0    0    0 \n",
      "(20)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  108    0    0 \n",
      "(21)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   93    0 \n",
      "(22)    0   37    0    0    0    0    0    0    0    0    0    0    0    0    0   18    0    0    0    0    0    0   43 \n",
      "Model: Pipeline\n",
      "Training Accuracy Score: 17.6%\n",
      "Validation Accuracy Score: 16.7%\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       banana       1.00      1.00      1.00       103\n",
      " black lentil       0.00      0.00      0.00       103\n",
      " bottle gourd       0.00      0.00      0.00       102\n",
      "      brinjal       0.00      0.00      0.00        99\n",
      "       carrot       1.00      1.00      1.00        87\n",
      "  cauliflower       0.00      0.00      0.00        95\n",
      "    chickpeas       0.00      0.00      0.00        89\n",
      "       chilli       0.00      0.00      0.00       108\n",
      "finger millet       0.00      0.00      0.00        90\n",
      "    groundnut       0.04      1.00      0.08        88\n",
      "  kidneybeans       1.00      1.00      1.00       107\n",
      "  lady finger       0.00      0.00      0.00       105\n",
      "        maize       0.00      0.00      0.00       109\n",
      "       millet       0.00      0.00      0.00       106\n",
      "       papaya       0.00      0.00      0.00       104\n",
      "   red lentil       0.00      0.00      0.00       106\n",
      "         rice       0.00      0.00      0.00       107\n",
      "      sorghum       0.00      0.00      0.00        99\n",
      "     soyabean       0.00      0.00      0.00       100\n",
      "       tomato       0.00      0.00      0.00        94\n",
      "  watermeleon       0.00      0.00      0.00       108\n",
      "        wheat       0.00      0.00      0.00        93\n",
      "yellow lentil       0.00      0.00      0.00        98\n",
      "\n",
      "     accuracy                           0.17      2300\n",
      "    macro avg       0.13      0.17      0.13      2300\n",
      " weighted avg       0.13      0.17      0.13      2300\n",
      "\n",
      "Confusion Matrix:\n",
      "     (0) (1) (2) (3) (4) (5) (6) (7) (8) (9) (10) (11) (12) (13) (14) (15) (16) (17) (18) (19) (20) (21) (22)\n",
      "(0)  103    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(1)    0    0    0    0    0    0    0    0    0  103    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(2)    0    0    0    0    0    0    0    0    0  102    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(3)    0    0    0    0    0    0    0    0    0   99    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(4)    0    0    0    0   87    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(5)    0    0    0    0    0    0    0    0    0   95    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(6)    0    0    0    0    0    0    0    0    0   89    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(7)    0    0    0    0    0    0    0    0    0  108    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(8)    0    0    0    0    0    0    0    0    0   90    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(9)    0    0    0    0    0    0    0    0    0   88    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(10)    0    0    0    0    0    0    0    0    0    0  107    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(11)    0    0    0    0    0    0    0    0    0  105    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(12)    0    0    0    0    0    0    0    0    0  109    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(13)    0    0    0    0    0    0    0    0    0  106    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(14)    0    0    0    0    0    0    0    0    0  104    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(15)    0    0    0    0    0    0    0    0    0  106    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(16)    0    0    0    0    0    0    0    0    0  107    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(17)    0    0    0    0    0    0    0    0    0   99    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(18)    0    0    0    0    0    0    0    0    0  100    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(19)    0    0    0    0    0    0    0    0    0   94    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(20)    0    0    0    0    0    0    0    0    0  108    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(21)    0    0    0    0    0    0    0    0    0   93    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(22)    0    0    0    0    0    0    0    0    0   98    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "Model: Pipeline\n",
      "Training Accuracy Score: 96.2%\n",
      "Validation Accuracy Score: 88.7%\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       banana       1.00      1.00      1.00       103\n",
      " black lentil       0.35      0.28      0.31       103\n",
      " bottle gourd       0.99      1.00      1.00       102\n",
      "      brinjal       1.00      1.00      1.00        99\n",
      "       carrot       1.00      1.00      1.00        87\n",
      "  cauliflower       1.00      0.99      0.99        95\n",
      "    chickpeas       1.00      1.00      1.00        89\n",
      "       chilli       1.00      0.99      1.00       108\n",
      "finger millet       0.89      0.60      0.72        90\n",
      "    groundnut       1.00      1.00      1.00        88\n",
      "  kidneybeans       1.00      1.00      1.00       107\n",
      "  lady finger       0.99      1.00      1.00       105\n",
      "        maize       1.00      1.00      1.00       109\n",
      "       millet       0.73      0.94      0.82       106\n",
      "       papaya       1.00      0.99      1.00       104\n",
      "   red lentil       0.32      0.29      0.31       106\n",
      "         rice       1.00      0.99      1.00       107\n",
      "      sorghum       1.00      1.00      1.00        99\n",
      "     soyabean       1.00      1.00      1.00       100\n",
      "       tomato       1.00      1.00      1.00        94\n",
      "  watermeleon       1.00      1.00      1.00       108\n",
      "        wheat       1.00      1.00      1.00        93\n",
      "yellow lentil       0.25      0.33      0.28        98\n",
      "\n",
      "     accuracy                           0.89      2300\n",
      "    macro avg       0.89      0.89      0.89      2300\n",
      " weighted avg       0.89      0.89      0.89      2300\n",
      "\n",
      "Confusion Matrix:\n",
      "     (0) (1) (2) (3) (4) (5) (6) (7) (8) (9) (10) (11) (12) (13) (14) (15) (16) (17) (18) (19) (20) (21) (22)\n",
      "(0)  103    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(1)    0   29    0    0    0    0    0    0    0    0    0    0    0    0    0   25    0    0    0    0    0    0   49 \n",
      "(2)    0    0  102    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(3)    0    0    0   99    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(4)    0    0    0    0   87    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(5)    0    0    0    0    0   94    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(6)    0    0    0    0    0    0   89    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(7)    0    0    0    0    0    0    0  107    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(8)    0    0    0    0    0    0    0    0   54    0    0    0    0   36    0    0    0    0    0    0    0    0    0 \n",
      "(9)    0    0    0    0    0    0    0    0    0   88    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(10)    0    0    0    0    0    0    0    0    0    0  107    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(11)    0    0    0    0    0    0    0    0    0    0    0  105    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(12)    0    0    0    0    0    0    0    0    0    0    0    0  109    0    0    0    0    0    0    0    0    0    0 \n",
      "(13)    0    0    0    0    0    0    0    0    6    0    0    0    0  100    0    0    0    0    0    0    0    0    0 \n",
      "(14)    0    0    1    0    0    0    0    0    0    0    0    0    0    0  103    0    0    0    0    0    0    0    0 \n",
      "(15)    0   28    0    0    0    0    0    0    0    0    0    0    0    0    0   31    0    0    0    0    0    0   47 \n",
      "(16)    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0  106    0    0    0    0    0    0 \n",
      "(17)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   99    0    0    0    0    0 \n",
      "(18)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  100    0    0    0    0 \n",
      "(19)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   94    0    0    0 \n",
      "(20)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  108    0    0 \n",
      "(21)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   93    0 \n",
      "(22)    0   26    0    0    0    0    0    0    0    0    0    0    0    0    0   40    0    0    0    0    0    0   32 \n",
      "Model: Pipeline\n",
      "Training Accuracy Score: 100.0%\n",
      "Validation Accuracy Score: 88.6%\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       banana       1.00      1.00      1.00       103\n",
      " black lentil       0.30      0.30      0.30       103\n",
      " bottle gourd       0.99      1.00      1.00       102\n",
      "      brinjal       1.00      1.00      1.00        99\n",
      "       carrot       1.00      1.00      1.00        87\n",
      "  cauliflower       1.00      1.00      1.00        95\n",
      "    chickpeas       1.00      1.00      1.00        89\n",
      "       chilli       1.00      0.99      1.00       108\n",
      "finger millet       0.93      0.61      0.74        90\n",
      "    groundnut       1.00      1.00      1.00        88\n",
      "  kidneybeans       1.00      1.00      1.00       107\n",
      "  lady finger       0.99      1.00      1.00       105\n",
      "        maize       1.00      1.00      1.00       109\n",
      "       millet       0.74      0.96      0.84       106\n",
      "       papaya       1.00      0.99      1.00       104\n",
      "   red lentil       0.28      0.28      0.28       106\n",
      "         rice       1.00      1.00      1.00       107\n",
      "      sorghum       1.00      1.00      1.00        99\n",
      "     soyabean       1.00      1.00      1.00       100\n",
      "       tomato       1.00      1.00      1.00        94\n",
      "  watermeleon       1.00      1.00      1.00       108\n",
      "        wheat       1.00      1.00      1.00        93\n",
      "yellow lentil       0.26      0.26      0.26        98\n",
      "\n",
      "     accuracy                           0.89      2300\n",
      "    macro avg       0.89      0.89      0.89      2300\n",
      " weighted avg       0.89      0.89      0.89      2300\n",
      "\n",
      "Confusion Matrix:\n",
      "     (0) (1) (2) (3) (4) (5) (6) (7) (8) (9) (10) (11) (12) (13) (14) (15) (16) (17) (18) (19) (20) (21) (22)\n",
      "(0)  103    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(1)    0   31    0    0    0    0    0    0    0    0    0    0    0    0    0   37    0    0    0    0    0    0   35 \n",
      "(2)    0    0  102    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(3)    0    0    0   99    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(4)    0    0    0    0   87    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(5)    0    0    0    0    0   95    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(6)    0    0    0    0    0    0   89    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(7)    0    0    0    0    0    0    0  107    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(8)    0    0    0    0    0    0    0    0   55    0    0    0    0   35    0    0    0    0    0    0    0    0    0 \n",
      "(9)    0    0    0    0    0    0    0    0    0   88    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(10)    0    0    0    0    0    0    0    0    0    0  107    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(11)    0    0    0    0    0    0    0    0    0    0    0  105    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(12)    0    0    0    0    0    0    0    0    0    0    0    0  109    0    0    0    0    0    0    0    0    0    0 \n",
      "(13)    0    0    0    0    0    0    0    0    4    0    0    0    0  102    0    0    0    0    0    0    0    0    0 \n",
      "(14)    0    0    1    0    0    0    0    0    0    0    0    0    0    0  103    0    0    0    0    0    0    0    0 \n",
      "(15)    0   38    0    0    0    0    0    0    0    0    0    0    0    0    0   30    0    0    0    0    0    0   38 \n",
      "(16)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  107    0    0    0    0    0    0 \n",
      "(17)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   99    0    0    0    0    0 \n",
      "(18)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  100    0    0    0    0 \n",
      "(19)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   94    0    0    0 \n",
      "(20)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  108    0    0 \n",
      "(21)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   93    0 \n",
      "(22)    0   34    0    0    0    0    0    0    0    0    0    0    0    0    0   39    0    0    0    0    0    0   25 \n",
      "Model: Pipeline\n",
      "Training Accuracy Score: 99.6%\n",
      "Validation Accuracy Score: 88.5%\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       banana       1.00      1.00      1.00       103\n",
      " black lentil       0.33      0.35      0.34       103\n",
      " bottle gourd       0.99      1.00      1.00       102\n",
      "      brinjal       1.00      1.00      1.00        99\n",
      "       carrot       1.00      1.00      1.00        87\n",
      "  cauliflower       1.00      0.99      0.99        95\n",
      "    chickpeas       1.00      1.00      1.00        89\n",
      "       chilli       0.99      0.99      0.99       108\n",
      "finger millet       0.79      0.64      0.71        90\n",
      "    groundnut       1.00      1.00      1.00        88\n",
      "  kidneybeans       1.00      1.00      1.00       107\n",
      "  lady finger       0.99      1.00      1.00       105\n",
      "        maize       1.00      1.00      1.00       109\n",
      "       millet       0.74      0.86      0.79       106\n",
      "       papaya       1.00      0.99      1.00       104\n",
      "   red lentil       0.27      0.25      0.26       106\n",
      "         rice       1.00      1.00      1.00       107\n",
      "      sorghum       1.00      1.00      1.00        99\n",
      "     soyabean       1.00      1.00      1.00       100\n",
      "       tomato       1.00      0.99      0.99        94\n",
      "  watermeleon       0.99      1.00      1.00       108\n",
      "        wheat       1.00      1.00      1.00        93\n",
      "yellow lentil       0.31      0.32      0.31        98\n",
      "\n",
      "     accuracy                           0.88      2300\n",
      "    macro avg       0.89      0.89      0.89      2300\n",
      " weighted avg       0.88      0.88      0.88      2300\n",
      "\n",
      "Confusion Matrix:\n",
      "     (0) (1) (2) (3) (4) (5) (6) (7) (8) (9) (10) (11) (12) (13) (14) (15) (16) (17) (18) (19) (20) (21) (22)\n",
      "(0)  103    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(1)    0   36    0    0    0    0    0    0    0    0    0    0    0    0    0   31    0    0    0    0    0    0   36 \n",
      "(2)    0    0  102    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(3)    0    0    0   99    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(4)    0    0    0    0   87    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(5)    0    0    0    0    0   94    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0 \n",
      "(6)    0    0    0    0    0    0   89    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(7)    0    0    0    0    0    0    0  107    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(8)    0    0    0    0    0    0    0    0   58    0    0    0    0   32    0    0    0    0    0    0    0    0    0 \n",
      "(9)    0    0    0    0    0    0    0    0    0   88    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(10)    0    0    0    0    0    0    0    0    0    0  107    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(11)    0    0    0    0    0    0    0    0    0    0    0  105    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(12)    0    0    0    0    0    0    0    0    0    0    0    0  109    0    0    0    0    0    0    0    0    0    0 \n",
      "(13)    0    0    0    0    0    0    0    0   15    0    0    0    0   91    0    0    0    0    0    0    0    0    0 \n",
      "(14)    0    0    1    0    0    0    0    0    0    0    0    0    0    0  103    0    0    0    0    0    0    0    0 \n",
      "(15)    0   47    0    0    0    0    0    0    0    0    0    0    0    0    0   26    0    0    0    0    0    0   33 \n",
      "(16)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  107    0    0    0    0    0    0 \n",
      "(17)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   99    0    0    0    0    0 \n",
      "(18)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  100    0    0    0    0 \n",
      "(19)    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0   93    0    0    0 \n",
      "(20)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  108    0    0 \n",
      "(21)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   93    0 \n",
      "(22)    0   27    0    0    0    0    0    0    0    0    0    0    0    0    0   40    0    0    0    0    0    0   31 \n",
      "Model: Pipeline\n",
      "Training Accuracy Score: 100.0%\n",
      "Validation Accuracy Score: 87.9%\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       banana       1.00      1.00      1.00       103\n",
      " black lentil       0.29      0.29      0.29       103\n",
      " bottle gourd       0.99      0.96      0.98       102\n",
      "      brinjal       0.99      1.00      0.99        99\n",
      "       carrot       1.00      1.00      1.00        87\n",
      "  cauliflower       1.00      1.00      1.00        95\n",
      "    chickpeas       1.00      1.00      1.00        89\n",
      "       chilli       0.97      1.00      0.99       108\n",
      "finger millet       0.76      0.61      0.68        90\n",
      "    groundnut       1.00      1.00      1.00        88\n",
      "  kidneybeans       1.00      1.00      1.00       107\n",
      "  lady finger       1.00      1.00      1.00       105\n",
      "        maize       1.00      1.00      1.00       109\n",
      "       millet       0.72      0.84      0.77       106\n",
      "       papaya       1.00      0.99      1.00       104\n",
      "   red lentil       0.28      0.25      0.27       106\n",
      "         rice       1.00      1.00      1.00       107\n",
      "      sorghum       1.00      0.99      0.99        99\n",
      "     soyabean       1.00      1.00      1.00       100\n",
      "       tomato       1.00      1.00      1.00        94\n",
      "  watermeleon       1.00      1.00      1.00       108\n",
      "        wheat       0.99      1.00      0.99        93\n",
      "yellow lentil       0.27      0.30      0.28        98\n",
      "\n",
      "     accuracy                           0.88      2300\n",
      "    macro avg       0.88      0.88      0.88      2300\n",
      " weighted avg       0.88      0.88      0.88      2300\n",
      "\n",
      "Confusion Matrix:\n",
      "     (0) (1) (2) (3) (4) (5) (6) (7) (8) (9) (10) (11) (12) (13) (14) (15) (16) (17) (18) (19) (20) (21) (22)\n",
      "(0)  103    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(1)    0   30    0    0    0    0    0    0    0    0    0    0    0    0    0   35    0    0    0    0    0    0   38 \n",
      "(2)    0    0   98    1    0    0    0    3    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(3)    0    0    0   99    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(4)    0    0    0    0   87    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(5)    0    0    0    0    0   95    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(6)    0    0    0    0    0    0   89    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(7)    0    0    0    0    0    0    0  108    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(8)    0    0    0    0    0    0    0    0   55    0    0    0    0   35    0    0    0    0    0    0    0    0    0 \n",
      "(9)    0    0    0    0    0    0    0    0    0   88    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(10)    0    0    0    0    0    0    0    0    0    0  107    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(11)    0    0    0    0    0    0    0    0    0    0    0  105    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(12)    0    0    0    0    0    0    0    0    0    0    0    0  109    0    0    0    0    0    0    0    0    0    0 \n",
      "(13)    0    0    0    0    0    0    0    0   17    0    0    0    0   89    0    0    0    0    0    0    0    0    0 \n",
      "(14)    0    0    1    0    0    0    0    0    0    0    0    0    0    0  103    0    0    0    0    0    0    0    0 \n",
      "(15)    0   40    0    0    0    0    0    0    0    0    0    0    0    0    0   27    0    0    0    0    0    0   39 \n",
      "(16)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  107    0    0    0    0    0    0 \n",
      "(17)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   98    0    0    0    1    0 \n",
      "(18)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  100    0    0    0    0 \n",
      "(19)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   94    0    0    0 \n",
      "(20)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  108    0    0 \n",
      "(21)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   93    0 \n",
      "(22)    0   35    0    0    0    0    0    0    0    0    0    0    0    0    0   34    0    0    0    0    0    0   29 \n",
      "Model: StackingClassifier\n",
      "Training Accuracy Score: 86.0%\n",
      "Validation Accuracy Score: 90.3%\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       banana       1.00      1.00      1.00       103\n",
      " black lentil       0.44      0.45      0.44       103\n",
      " bottle gourd       0.99      1.00      1.00       102\n",
      "      brinjal       1.00      1.00      1.00        99\n",
      "       carrot       1.00      1.00      1.00        87\n",
      "  cauliflower       1.00      1.00      1.00        95\n",
      "    chickpeas       1.00      1.00      1.00        89\n",
      "       chilli       1.00      0.99      1.00       108\n",
      "finger millet       0.96      0.60      0.74        90\n",
      "    groundnut       1.00      1.00      1.00        88\n",
      "  kidneybeans       1.00      1.00      1.00       107\n",
      "  lady finger       0.99      1.00      1.00       105\n",
      "        maize       1.00      1.00      1.00       109\n",
      "       millet       0.74      0.98      0.85       106\n",
      "       papaya       1.00      0.99      1.00       104\n",
      "   red lentil       0.42      0.39      0.40       106\n",
      "         rice       1.00      1.00      1.00       107\n",
      "      sorghum       1.00      1.00      1.00        99\n",
      "     soyabean       1.00      1.00      1.00       100\n",
      "       tomato       1.00      1.00      1.00        94\n",
      "  watermeleon       1.00      1.00      1.00       108\n",
      "        wheat       1.00      1.00      1.00        93\n",
      "yellow lentil       0.37      0.39      0.38        98\n",
      "\n",
      "     accuracy                           0.90      2300\n",
      "    macro avg       0.91      0.90      0.90      2300\n",
      " weighted avg       0.91      0.90      0.90      2300\n",
      "\n",
      "Confusion Matrix:\n",
      "     (0) (1) (2) (3) (4) (5) (6) (7) (8) (9) (10) (11) (12) (13) (14) (15) (16) (17) (18) (19) (20) (21) (22)\n",
      "(0)  103    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(1)    0   46    0    0    0    0    0    0    0    0    0    0    0    0    0   28    0    0    0    0    0    0   29 \n",
      "(2)    0    0  102    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(3)    0    0    0   99    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(4)    0    0    0    0   87    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(5)    0    0    0    0    0   95    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(6)    0    0    0    0    0    0   89    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(7)    0    0    0    0    0    0    0  107    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(8)    0    0    0    0    0    0    0    0   54    0    0    0    0   36    0    0    0    0    0    0    0    0    0 \n",
      "(9)    0    0    0    0    0    0    0    0    0   88    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(10)    0    0    0    0    0    0    0    0    0    0  107    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(11)    0    0    0    0    0    0    0    0    0    0    0  105    0    0    0    0    0    0    0    0    0    0    0 \n",
      "(12)    0    0    0    0    0    0    0    0    0    0    0    0  109    0    0    0    0    0    0    0    0    0    0 \n",
      "(13)    0    0    0    0    0    0    0    0    2    0    0    0    0  104    0    0    0    0    0    0    0    0    0 \n",
      "(14)    0    0    1    0    0    0    0    0    0    0    0    0    0    0  103    0    0    0    0    0    0    0    0 \n",
      "(15)    0   28    0    0    0    0    0    0    0    0    0    0    0    0    0   41    0    0    0    0    0    0   37 \n",
      "(16)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  107    0    0    0    0    0    0 \n",
      "(17)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   99    0    0    0    0    0 \n",
      "(18)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  100    0    0    0    0 \n",
      "(19)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   94    0    0    0 \n",
      "(20)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  108    0    0 \n",
      "(21)    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   93    0 \n",
      "(22)    0   31    0    0    0    0    0    0    0    0    0    0    0    0    0   29    0    0    0    0    0    0   38 \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed = 42\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r\"E:\\Crop Prediction\\DataSet New.csv\")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "# Define target variable and split data\n",
    "target = 'label'\n",
    "X = df.drop(target, axis=1)\n",
    "y = df[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Spot-Check Algorithms\n",
    "models = [\n",
    "    ('LR', LogisticRegression(solver='saga', max_iter=1000)),\n",
    "    ('LDA', LinearDiscriminantAnalysis()),\n",
    "    ('KNN', KNeighborsClassifier()),\n",
    "    ('CART', DecisionTreeClassifier()),\n",
    "    ('NB', GaussianNB()),\n",
    "    ('SVM', SVC(probability=True))\n",
    "]\n",
    "\n",
    "# Define ensemble models\n",
    "ensembles = [\n",
    "    ('AB', AdaBoostClassifier()),\n",
    "    ('GBM', GradientBoostingClassifier()),\n",
    "    ('RF', RandomForestClassifier()),\n",
    "    ('Bagging', BaggingClassifier()),\n",
    "    ('ET', ExtraTreesClassifier())\n",
    "]\n",
    "\n",
    "# Function to perform hyperparameter tuning\n",
    "def perform_hyperparameter_tuning(model, X_train, y_train):\n",
    "    return model  # Placeholder, implement grid search here\n",
    "\n",
    "# Function to perform feature selection\n",
    "def select_features(model, X_train, y_train):\n",
    "    return X_train  # Placeholder, implement feature selection here\n",
    "\n",
    "# Function to train a model\n",
    "def train_model(model, X_train, y_train):\n",
    "    pipeline = make_pipeline(StandardScaler(), model)\n",
    "    trained_model = pipeline.fit(X_train, y_train)\n",
    "    return trained_model\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def evaluate_model(trained_model, X_test, y_test):\n",
    "    y_pred = trained_model.predict(X_test)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Model: {type(trained_model).__name__}\")\n",
    "    print(f\"Training Accuracy Score: {trained_model.score(X_train, y_train) * 100:.1f}%\")\n",
    "    print(f\"Validation Accuracy Score: {trained_model.score(X_test, y_test) * 100:.1f}%\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(\"    \", \" \".join(f\"({i})\" for i in range(conf_matrix.shape[0])))\n",
    "    for i, row in enumerate(conf_matrix):\n",
    "        print(f\"({i})\", end=\" \")\n",
    "        for value in row:\n",
    "            print(f\"{value:4}\", end=\" \")\n",
    "        print()\n",
    "    return trained_model\n",
    "\n",
    "\n",
    "# Step 1: Combine Models and Train\n",
    "all_models = models + ensembles\n",
    "trained_models = {}\n",
    "\n",
    "for model_name, model_instance in all_models:\n",
    "    # Step 2: Hyperparameter Tuning\n",
    "    tuned_model = perform_hyperparameter_tuning(model_instance, X_train, y_train)\n",
    "\n",
    "    # Step 3: Feature Selection\n",
    "    selected_features = select_features(tuned_model, X_train, y_train)\n",
    "\n",
    "    # Step 4: Train Models\n",
    "    trained_model = train_model(tuned_model, selected_features, y_train)\n",
    "    trained_models[model_name] = trained_model\n",
    "\n",
    "# Step 5: Ensemble Methods (Stacking)\n",
    "stacked_model = StackingClassifier(estimators=all_models, final_estimator=LogisticRegression())\n",
    "\n",
    "# Step 6: Evaluate Model Performance\n",
    "for model_name, trained_model in trained_models.items():\n",
    "    evaluate_model(trained_model, X_test, y_test)\n",
    "\n",
    "# Step 7: Fit the Stacked Model\n",
    "stacked_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 8: Evaluate the Stacked Model\n",
    "evaluate_model(stacked_model, X_test, y_test)\n",
    "\n",
    "# Step 9: Select the Best Model\n",
    "best_model = stacked_model  # Placeholder, select the best model based on performance\n",
    "\n",
    "# Step 10: Fine-Tuning and Validation (if needed)\n",
    "\n",
    "# Step 11: Save the Overall Model\n",
    "def save_model(model,filename):\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "# save model\n",
    "save_model(best_model, 'overall_model.pkl')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8800472-c087-49d9-bf90-ba980c6c94d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
